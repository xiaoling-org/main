{
  "model": "ollama/qwen2.5:1.5b-instruct",
  "apiBase": "http://localhost:11434/v1",
  "fallbackModel": "deepseek/deepseek-chat",
  "maxTokens": 2048,
  "temperature": 0.7,
  "timeout": 30000,
  "retryCount": 2,
  "priority": "local-first",
  "gpuAcceleration": true,
  "memoryLimitMB": 4096
}