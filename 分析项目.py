#!/usr/bin/env python3
"""
é¡¹ç›®åˆ†æžè„šæœ¬
ç”¨äºŽåˆ†æžLotteryAnalysisToolå’ŒOmniMarket-Financial-Monitoré¡¹ç›®
"""

import os
import json
from datetime import datetime
from pathlib import Path
import subprocess
import sys

class ProjectAnalyzer:
    def __init__(self):
        self.base_dir = Path("C:/Users/czp/openclaw/projects/github")
        self.results = {}
        
    def analyze_project(self, project_name):
        """åˆ†æžå•ä¸ªé¡¹ç›®"""
        print(f"\nðŸ” å¼€å§‹åˆ†æžé¡¹ç›®: {project_name}")
        print("=" * 60)
        
        project_path = self.base_dir / project_name
        if not project_path.exists():
            print(f"âŒ é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_path}")
            return None
        
        result = {
            "project_name": project_name,
            "analysis_time": datetime.now().isoformat(),
            "project_path": str(project_path),
            "file_stats": {},
            "structure": {},
            "tech_stack": {},
            "issues": [],
            "recommendations": []
        }
        
        # 1. åŸºæœ¬æ–‡ä»¶ç»Ÿè®¡
        result["file_stats"] = self.analyze_file_stats(project_path)
        
        # 2. é¡¹ç›®ç»“æž„åˆ†æž
        result["structure"] = self.analyze_structure(project_path)
        
        # 3. æŠ€æœ¯æ ˆåˆ†æž
        result["tech_stack"] = self.analyze_tech_stack(project_path)
        
        # 4. é—®é¢˜è¯†åˆ«
        result["issues"] = self.identify_issues(project_path, result)
        
        # 5. æ”¹è¿›å»ºè®®
        result["recommendations"] = self.generate_recommendations(result)
        
        self.results[project_name] = result
        return result
    
    def analyze_file_stats(self, project_path):
        """åˆ†æžæ–‡ä»¶ç»Ÿè®¡"""
        stats = {
            "total_files": 0,
            "total_size_mb": 0,
            "file_types": {},
            "largest_files": []
        }
        
        try:
            for root, dirs, files in os.walk(project_path):
                for file in files:
                    file_path = Path(root) / file
                    stats["total_files"] += 1
                    
                    # æ–‡ä»¶å¤§å°
                    try:
                        file_size = file_path.stat().st_size
                        stats["total_size_mb"] += file_size / (1024 * 1024)
                    except:
                        pass
                    
                    # æ–‡ä»¶ç±»åž‹ç»Ÿè®¡
                    ext = file_path.suffix.lower()
                    if ext:
                        stats["file_types"][ext] = stats["file_types"].get(ext, 0) + 1
                    else:
                        stats["file_types"]["no_extension"] = stats["file_types"].get("no_extension", 0) + 1
                    
                    # è®°å½•å¤§æ–‡ä»¶
                    if file_size > 1024 * 1024:  # å¤§äºŽ1MB
                        stats["largest_files"].append({
                            "path": str(file_path.relative_to(project_path)),
                            "size_mb": round(file_size / (1024 * 1024), 2)
                        })
            
            stats["total_size_mb"] = round(stats["total_size_mb"], 2)
            # åªä¿ç•™å‰10ä¸ªå¤§æ–‡ä»¶
            stats["largest_files"] = sorted(stats["largest_files"], key=lambda x: x["size_mb"], reverse=True)[:10]
            
        except Exception as e:
            print(f"æ–‡ä»¶ç»Ÿè®¡é”™è¯¯: {e}")
        
        return stats
    
    def analyze_structure(self, project_path):
        """åˆ†æžé¡¹ç›®ç»“æž„"""
        structure = {
            "directories": [],
            "key_files": [],
            "readme_exists": False,
            "gitignore_exists": False,
            "requirements_exists": False
        }
        
        try:
            # æ£€æŸ¥å…³é”®æ–‡ä»¶
            key_files = ["README.md", "README.txt", "README", "readme.md"]
            req_files = ["requirements.txt", "Pipfile", "pyproject.toml", "package.json"]
            
            for item in project_path.iterdir():
                if item.is_dir():
                    structure["directories"].append(item.name)
                else:
                    structure["key_files"].append(item.name)
                    
                    # æ£€æŸ¥README
                    if item.name.lower() in [f.lower() for f in key_files]:
                        structure["readme_exists"] = True
                    
                    # æ£€æŸ¥.gitignore
                    if item.name == ".gitignore":
                        structure["gitignore_exists"] = True
                    
                    # æ£€æŸ¥ä¾èµ–æ–‡ä»¶
                    if item.name.lower() in [f.lower() for f in req_files]:
                        structure["requirements_exists"] = True
            
            # åªæ˜¾ç¤ºå‰10ä¸ªç›®å½•å’Œæ–‡ä»¶
            structure["directories"] = structure["directories"][:10]
            structure["key_files"] = structure["key_files"][:15]
            
        except Exception as e:
            print(f"ç»“æž„åˆ†æžé”™è¯¯: {e}")
        
        return structure
    
    def analyze_tech_stack(self, project_path):
        """åˆ†æžæŠ€æœ¯æ ˆ"""
        tech_stack = {
            "languages": {},
            "frameworks": [],
            "databases": [],
            "tools": []
        }
        
        try:
            # é€šè¿‡æ–‡ä»¶æ‰©å±•åè¯†åˆ«è¯­è¨€
            ext_to_lang = {
                ".py": "Python",
                ".js": "JavaScript",
                ".ts": "TypeScript",
                ".java": "Java",
                ".cpp": "C++",
                ".c": "C",
                ".cs": "C#",
                ".go": "Go",
                ".rs": "Rust",
                ".php": "PHP",
                ".html": "HTML",
                ".css": "CSS",
                ".sql": "SQL",
                ".json": "JSON",
                ".yml": "YAML",
                ".yaml": "YAML",
                ".toml": "TOML",
                ".md": "Markdown",
                ".txt": "Text"
            }
            
            for root, dirs, files in os.walk(project_path):
                for file in files:
                    ext = Path(file).suffix.lower()
                    if ext in ext_to_lang:
                        lang = ext_to_lang[ext]
                        tech_stack["languages"][lang] = tech_stack["languages"].get(lang, 0) + 1
            
            # æ£€æŸ¥æ¡†æž¶å’Œå·¥å…·
            framework_indicators = {
                "django": ["settings.py", "urls.py", "wsgi.py"],
                "flask": ["app.py", "flask_app.py"],
                "react": ["package.json", "node_modules"],
                "vue": ["vue.config.js"],
                "angular": ["angular.json"],
                "spring": ["pom.xml", "build.gradle"],
                "express": ["package.json"],
                "fastapi": ["main.py"]
            }
            
            for root, dirs, files in os.walk(project_path):
                for file in files:
                    file_lower = file.lower()
                    
                    # æ£€æŸ¥æ•°æ®åº“
                    if "sqlite" in file_lower:
                        tech_stack["databases"].append("SQLite")
                    elif "postgres" in file_lower:
                        tech_stack["databases"].append("PostgreSQL")
                    elif "mysql" in file_lower:
                        tech_stack["databases"].append("MySQL")
                    elif "mongodb" in file_lower:
                        tech_stack["databases"].append("MongoDB")
                    
                    # æ£€æŸ¥å·¥å…·
                    if "docker" in file_lower:
                        tech_stack["tools"].append("Docker")
                    elif "dockerfile" in file_lower:
                        tech_stack["tools"].append("Docker")
                    elif "docker-compose" in file_lower:
                        tech_stack["tools"].append("Docker Compose")
            
            # åŽ»é‡
            tech_stack["databases"] = list(set(tech_stack["databases"]))
            tech_stack["tools"] = list(set(tech_stack["tools"]))
            
        except Exception as e:
            print(f"æŠ€æœ¯æ ˆåˆ†æžé”™è¯¯: {e}")
        
        return tech_stack
    
    def identify_issues(self, project_path, analysis_result):
        """è¯†åˆ«é—®é¢˜"""
        issues = []
        
        try:
            # æ£€æŸ¥README
            if not analysis_result["structure"]["readme_exists"]:
                issues.append({
                    "type": "documentation",
                    "severity": "medium",
                    "description": "ç¼ºå°‘READMEæ–‡æ¡£",
                    "suggestion": "åˆ›å»ºREADME.mdæ–‡ä»¶ï¼Œæè¿°é¡¹ç›®ç”¨é€”ã€å®‰è£…å’Œä½¿ç”¨æ–¹æ³•"
                })
            
            # æ£€æŸ¥.gitignore
            if not analysis_result["structure"]["gitignore_exists"]:
                issues.append({
                    "type": "best_practice",
                    "severity": "low",
                    "description": "ç¼ºå°‘.gitignoreæ–‡ä»¶",
                    "suggestion": "åˆ›å»º.gitignoreæ–‡ä»¶ï¼ŒæŽ’é™¤ä¸å¿…è¦çš„æ–‡ä»¶"
                })
            
            # æ£€æŸ¥ä¾èµ–ç®¡ç†
            if not analysis_result["structure"]["requirements_exists"]:
                issues.append({
                    "type": "dependency",
                    "severity": "medium",
                    "description": "ç¼ºå°‘ä¾èµ–ç®¡ç†æ–‡ä»¶",
                    "suggestion": "æ·»åŠ requirements.txtæˆ–ç±»ä¼¼æ–‡ä»¶ç®¡ç†ä¾èµ–"
                })
            
            # æ£€æŸ¥å¤§æ–‡ä»¶
            large_files = analysis_result["file_stats"]["largest_files"]
            if large_files:
                for file_info in large_files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå¤§æ–‡ä»¶
                    issues.append({
                        "type": "performance",
                        "severity": "low",
                        "description": f"å‘çŽ°å¤§æ–‡ä»¶: {file_info['path']} ({file_info['size_mb']}MB)",
                        "suggestion": "è€ƒè™‘æ˜¯å¦å¯ä»¥å°†å¤§æ–‡ä»¶åˆ†å‰²æˆ–åŽ‹ç¼©"
                    })
            
            # æ£€æŸ¥ä»£ç æ–‡ä»¶æ¯”ä¾‹
            total_files = analysis_result["file_stats"]["total_files"]
            code_files = sum(count for ext, count in analysis_result["file_stats"]["file_types"].items() 
                           if ext in [".py", ".js", ".ts", ".java", ".cpp", ".c", ".go", ".rs", ".php"])
            
            if total_files > 0:
                code_ratio = code_files / total_files
                if code_ratio < 0.1:  # ä»£ç æ–‡ä»¶æ¯”ä¾‹ä½ŽäºŽ10%
                    issues.append({
                        "type": "structure",
                        "severity": "low",
                        "description": f"ä»£ç æ–‡ä»¶æ¯”ä¾‹è¾ƒä½Ž ({code_ratio:.1%})",
                        "suggestion": "æ£€æŸ¥é¡¹ç›®ç»“æž„ï¼Œç¡®ä¿ä»£ç æ–‡ä»¶ç»„ç»‡åˆç†"
                    })
            
        except Exception as e:
            print(f"é—®é¢˜è¯†åˆ«é”™è¯¯: {e}")
        
        return issues
    
    def generate_recommendations(self, analysis_result):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        try:
            project_name = analysis_result["project_name"]
            
            # åŸºç¡€å»ºè®®
            recommendations.append({
                "priority": "high",
                "category": "documentation",
                "description": "å®Œå–„é¡¹ç›®æ–‡æ¡£",
                "action": "åˆ›å»ºå®Œæ•´çš„README.mdï¼ŒåŒ…æ‹¬é¡¹ç›®ä»‹ç»ã€å®‰è£…æ­¥éª¤ã€ä½¿ç”¨ç¤ºä¾‹"
            })
            
            # æ ¹æ®é¡¹ç›®ç±»åž‹ç»™å‡ºå»ºè®®
            if "å½©ç¥¨" in project_name.lower() or "lottery" in project_name.lower():
                recommendations.append({
                    "priority": "medium",
                    "category": "feature",
                    "description": "å¢žå¼ºæ•°æ®åˆ†æžåŠŸèƒ½",
                    "action": "æ·»åŠ æ›´å¤šæ•°æ®åˆ†æžç®—æ³•å’Œå¯è§†åŒ–å›¾è¡¨"
                })
            
            if "é‡‘èž" in project_name.lower() or "financial" in project_name.lower() or "market" in project_name.lower():
                recommendations.append({
                    "priority": "high",
                    "category": "security",
                    "description": "åŠ å¼ºæ•°æ®å®‰å…¨",
                    "action": "æ·»åŠ æ•°æ®åŠ å¯†å’Œè®¿é—®æŽ§åˆ¶æœºåˆ¶"
                })
            
            # æŠ€æœ¯æ ˆå»ºè®®
            languages = list(analysis_result["tech_stack"]["languages"].keys())
            if "Python" in languages:
                recommendations.append({
                    "priority": "medium",
                    "category": "development",
                    "description": "æ·»åŠ æµ‹è¯•æ¡†æž¶",
                    "action": "é…ç½®pytestæˆ–unittestï¼Œæ·»åŠ å•å…ƒæµ‹è¯•"
                })
            
            if "JavaScript" in languages or "TypeScript" in languages:
                recommendations.append({
                    "priority": "medium",
                    "category": "development",
                    "description": "æ·»åŠ ä»£ç æ£€æŸ¥",
                    "action": "é…ç½®ESLintæˆ–Prettierï¼Œç»Ÿä¸€ä»£ç é£Žæ ¼"
                })
            
            # éƒ¨ç½²å»ºè®®
            recommendations.append({
                "priority": "low",
                "category": "deployment",
                "description": "ç®€åŒ–éƒ¨ç½²æµç¨‹",
                "action": "åˆ›å»ºéƒ¨ç½²è„šæœ¬æˆ–Dockeré…ç½®"
            })
            
        except Exception as e:
            print(f"å»ºè®®ç”Ÿæˆé”™è¯¯: {e}")
        
        return recommendations
    
    def print_summary(self, result):
        """æ‰“å°åˆ†æžæ‘˜è¦"""
        print(f"\nðŸ“Š é¡¹ç›®: {result['project_name']}")
        print(f"ðŸ“… åˆ†æžæ—¶é—´: {result['analysis_time']}")
        print(f"ðŸ“ é¡¹ç›®è·¯å¾„: {result['project_path']}")
        
        # æ–‡ä»¶ç»Ÿè®¡
        stats = result['file_stats']
        print(f"\nðŸ“ˆ æ–‡ä»¶ç»Ÿè®¡:")
        print(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   æ€»å¤§å°: {stats['total_size_mb']} MB")
        
        if stats['file_types']:
            print(f"   æ–‡ä»¶ç±»åž‹åˆ†å¸ƒ:")
            for ext, count in sorted(stats['file_types'].items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"     {ext}: {count} ä¸ª")
        
        # æŠ€æœ¯æ ˆ
        tech = result['tech_stack']
        if tech['languages']:
            print(f"\nðŸ’» æŠ€æœ¯æ ˆ:")
            print(f"   ç¼–ç¨‹è¯­è¨€: {', '.join(tech['languages'].keys())}")
        
        if tech['databases']:
            print(f"   æ•°æ®åº“: {', '.join(tech['databases'])}")
        
        if tech['tools']:
            print(f"   å·¥å…·: {', '.join(tech['tools'])}")
        
        # é—®é¢˜
        if result['issues']:
            print(f"\nâš ï¸  å‘çŽ°çš„é—®é¢˜ ({len(result['issues'])}ä¸ª):")
            for i, issue in enumerate(result['issues'][:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"   {i}. [{issue['severity'].upper()}] {issue['description']}")
        
        # å»ºè®®
        if result['recommendations']:
            print(f"\nðŸ’¡ æ”¹è¿›å»ºè®® ({len(result['recommendations'])}ä¸ª):")
            for i, rec in enumerate(result['recommendations'][:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"   {i}. [{rec['priority'].upper()}] {rec['description']}")
        
        print("\n" + "=" * 60)
    
    def save_results(self):
        """ä¿å­˜åˆ†æžç»“æžœ"""
        output_dir = Path("C:/Users/czp/openclaw/projects/analysis")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æžœ
        json_path = output_dir / f"project_analysis_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ–‡æœ¬æ ¼å¼çš„æ‘˜è¦
        txt_path = output_dir / f"project_summary_{timestamp}.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(f"é¡¹ç›®åˆ†æžæŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 60 + "\n\n")
            
            for project_name, result in self.results.items():
                f.write(f"é¡¹ç›®: {project_name}\n")
                f.write(f"åˆ†æžæ—¶é—´: {result['analysis_time']}\n")
                f.write(f"æ–‡ä»¶æ•°: {result['file_stats']['total_files']}\n")
                f.write(f"å¤§å°: {result['file_stats']['total_size_mb']} MB\n")
                
                if result['issues']:
                    f.write(f"å‘çŽ°é—®é¢˜: {len(result['issues'])}ä¸ª\n")
                
                if result['recommendations']:
                    f.write(f"æ”¹è¿›å»ºè®®: {len(result['recommendations'])}ä¸ª\n")
                
                f.write("\n" + "-" * 40 + "\n\n")
        
        print(f"\nðŸ’¾ åˆ†æžç»“æžœå·²ä¿å­˜:")
        print(f"   è¯¦ç»†ç»“æžœ: {json_path}")
        print(f"   æ‘˜è¦æŠ¥å‘Š: {txt_path}")
        
        return str(json_path), str(txt_path)
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æž"""
        print("ðŸš€ å¼€å§‹é¡¹ç›®åˆ†æž")
        print("=" * 60)
        
        projects = ["LotteryAnalysisTool", "OmniMarket-Financial-Monitor"]
        
        for project in projects:
            result = self.analyze_project(project)
            if result:
                self.print_summary(result)
        
        # ä¿å­˜ç»“æžœ
        json_path, txt_path = self.save_results()
        
        print("\nðŸŽ‰ é¡¹ç›®åˆ†æžå®Œæˆ!")
        print("=" * 60)
        
        return self.results

def main():
    """ä¸»å‡½æ•°"""
    try:
        analyzer = ProjectAnalyzer()
        results = analyzer.run_analysis()
        
        print("\nðŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. æŸ¥çœ‹è¯¦ç»†åˆ†æžæŠ¥å‘Šäº†è§£å…·ä½“é—®é¢˜")
        print("2. æ ¹æ®ä¼˜å…ˆçº§å®žæ–½æ”¹è¿›å»ºè®®")
        print("3. å®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥å’Œä¼˜åŒ–")
        print("4. è€ƒè™‘æ·»åŠ è‡ªåŠ¨åŒ–æµ‹è¯•å’Œéƒ¨ç½²")
        
        return 0
        
    except Exception as e:
        print(f"åˆ†æžå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())