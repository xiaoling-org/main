#!/usr/bin/env python3
"""
æ£€æŸ¥æ¥æ”¶çš„æ–‡ä»¶æ ¼å¼
"""

import os
import json

def check_file_format(file_path):
    """æ£€æŸ¥æ–‡ä»¶æ ¼å¼"""
    print(f"ğŸ“ æ£€æŸ¥æ–‡ä»¶: {file_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # è·å–æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(file_path)
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024:.2f} KB)")
    
    # è¯»å–æ–‡ä»¶å¼€å¤´åˆ¤æ–­æ ¼å¼
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()
            second_line = f.readline().strip()
            
        print(f"ğŸ“ ç¬¬ä¸€è¡Œ: {first_line[:100]}...")
        print(f"ğŸ“ ç¬¬äºŒè¡Œ: {second_line[:100]}...")
        
        # åˆ¤æ–­æ–‡ä»¶ç±»å‹
        if first_line.startswith('<!DOCTYPE html>'):
            print("ğŸ” æ–‡ä»¶ç±»å‹: HTML (Telegramå¯¼å‡ºçš„HTMLæ ¼å¼)")
            return 'html'
        elif first_line.startswith('{') or second_line.startswith('{'):
            print("ğŸ” æ–‡ä»¶ç±»å‹: JSON")
            return 'json'
        else:
            print("ğŸ” æ–‡ä»¶ç±»å‹: æœªçŸ¥")
            return 'unknown'
            
    except UnicodeDecodeError:
        # å¯èƒ½æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶
        with open(file_path, 'rb') as f:
            header = f.read(100)
        print(f"ğŸ” äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå¤´éƒ¨: {header[:50]}...")
        return 'binary'
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶é”™è¯¯: {e}")
        return False

def extract_html_content(file_path):
    """ä»HTMLæ–‡ä»¶ä¸­æå–å¯¹è¯å†…å®¹"""
    print("\nğŸ”§ å¼€å§‹è§£æHTMLæ–‡ä»¶...")
    
    try:
        from bs4 import BeautifulSoup
        import re
        from datetime import datetime
        
        # è¯»å–HTMLæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # ä½¿ç”¨BeautifulSoupè§£æ
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æŸ¥æ‰¾æ¶ˆæ¯å®¹å™¨
        messages = []
        
        # å°è¯•ä¸åŒçš„é€‰æ‹©å™¨
        # Telegramå¯¼å‡ºçš„HTMLé€šå¸¸æœ‰ç‰¹å®šçš„ç±»å
        message_divs = soup.find_all('div', class_=re.compile(r'message|msg'))
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(message_divs)} ä¸ªæ¶ˆæ¯å…ƒç´ ")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        if len(message_divs) == 0:
            # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ—¥æœŸå’Œæ–‡æœ¬çš„div
            all_divs = soup.find_all('div')
            print(f"ğŸ“Š æ€»divæ•°é‡: {len(all_divs)}")
            
            # ç®€å•æå–ï¼šæŸ¥æ‰¾åŒ…å«æ—¶é—´çš„div
            for div in all_divs[:50]:  # å…ˆçœ‹å‰50ä¸ª
                text = div.get_text(strip=True)
                if re.search(r'\d{1,2}:\d{2}', text) and len(text) < 100:
                    print(f"  å¯èƒ½çš„æ¶ˆæ¯: {text[:80]}...")
        
        return messages
        
    except ImportError:
        print("âŒ éœ€è¦BeautifulSoupåº“ï¼Œä½¿ç”¨ç®€å•æ–‡æœ¬æå–")
        
        # ç®€å•æ–‡æœ¬æå–
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æ—¥æœŸå’Œæ¶ˆæ¯çš„ç®€å•æ–¹æ³•
        import re
        
        # æŸ¥æ‰¾æ—¥æœŸæ¨¡å¼
        date_pattern = r'(\d{4}-\d{2}-\d{2})'
        dates = re.findall(date_pattern, content)
        
        print(f"ğŸ“… æ‰¾åˆ° {len(set(dates))} ä¸ªä¸åŒæ—¥æœŸ")
        if dates:
            print(f"  æœ€æ—©æ—¥æœŸ: {min(dates)}")
            print(f"  æœ€æ™šæ—¥æœŸ: {max(dates)}")
        
        return []

if __name__ == "__main__":
    file_path = r'C:\Users\czp\.openclaw\media\inbound\c4439bcc-0a0a-4b88-82c4-951afe98e1fb'
    
    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    file_type = check_file_format(file_path)
    
    if file_type == 'html':
        messages = extract_html_content(file_path)
        print(f"\nâœ… HTMLæ–‡ä»¶æ£€æŸ¥å®Œæˆ")
    else:
        print(f"\nğŸ“‹ æ–‡ä»¶ç±»å‹: {file_type}")