"""
å®æ—¶æ•°æ®ç³»ç»Ÿ
ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯æœ€æ–°å’Œå®æ—¶çš„
"""

import asyncio
import aiohttp
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from enum import Enum

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataFreshness(Enum):
    """æ•°æ®æ–°é²œåº¦ç­‰çº§"""
    REALTIME = "realtime"      # <1åˆ†é’Ÿ
    NEAR_REALTIME = "near_realtime"  # <5åˆ†é’Ÿ
    RECENT = "recent"         # <15åˆ†é’Ÿ
    STALE = "stale"           # >15åˆ†é’Ÿ

@dataclass
class RealTimeDataConfig:
    """å®æ—¶æ•°æ®é…ç½®"""
    data_type: str
    refresh_interval_seconds: int
    max_age_seconds: int
    required_freshness: DataFreshness
    retry_count: int = 3
    retry_delay_seconds: int = 2

class RealTimeDataSystem:
    """å®æ—¶æ•°æ®ç³»ç»Ÿ"""
    
    def __init__(self):
        # æ•°æ®é…ç½®
        self.data_configs = {
            'financial_market': RealTimeDataConfig(
                data_type='financial_market',
                refresh_interval_seconds=30,  # æ¯30ç§’åˆ·æ–°
                max_age_seconds=300,  # 5åˆ†é’Ÿæœ€å¤§å¹´é¾„
                required_freshness=DataFreshness.NEAR_REALTIME
            ),
            'stock_prices': RealTimeDataConfig(
                data_type='stock_prices',
                refresh_interval_seconds=10,  # æ¯10ç§’åˆ·æ–°
                max_age_seconds=60,  # 1åˆ†é’Ÿæœ€å¤§å¹´é¾„
                required_freshness=DataFreshness.REALTIME
            ),
            'crypto_prices': RealTimeDataConfig(
                data_type='crypto_prices',
                refresh_interval_seconds=5,  # æ¯5ç§’åˆ·æ–°
                max_age_seconds=30,  # 30ç§’æœ€å¤§å¹´é¾„
                required_freshness=DataFreshness.REALTIME
            ),
            'news': RealTimeDataConfig(
                data_type='news',
                refresh_interval_seconds=60,  # æ¯60ç§’åˆ·æ–°
                max_age_seconds=600,  # 10åˆ†é’Ÿæœ€å¤§å¹´é¾„
                required_freshness=DataFreshness.RECENT
            ),
            'economic_indicators': RealTimeDataConfig(
                data_type='economic_indicators',
                refresh_interval_seconds=300,  # æ¯5åˆ†é’Ÿåˆ·æ–°
                max_age_seconds=1800,  # 30åˆ†é’Ÿæœ€å¤§å¹´é¾„
                required_freshness=DataFreshness.NEAR_REALTIME
            )
        }
        
        # æ•°æ®ç¼“å­˜
        self.data_cache: Dict[str, Dict[str, Any]] = {}
        
        # æ•°æ®æºçŠ¶æ€
        self.source_status: Dict[str, Dict[str, Any]] = {}
        
        # è®¢é˜…è€…åˆ—è¡¨
        self.subscribers: Dict[str, List[callable]] = {}
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        
    async def fetch_realtime_data(self, data_type: str, url: str, params: Optional[Dict] = None) -> Dict[str, Any]:
        """è·å–å®æ—¶æ•°æ®"""
        config = self.data_configs.get(data_type)
        if not config:
            raise ValueError(f"æœªçŸ¥çš„æ•°æ®ç±»å‹: {data_type}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json'
        }
        
        for attempt in range(config.retry_count):
            try:
                async with aiohttp.ClientSession() as session:
                    timeout = aiohttp.ClientTimeout(total=10)
                    
                    async with session.get(url, params=params, headers=headers, timeout=timeout) as response:
                        if response.status == 200:
                            data = await response.json()
                            
                            # æ·»åŠ æ—¶é—´æˆ³å’Œå…ƒæ•°æ®
                            enriched_data = {
                                'data': data,
                                'metadata': {
                                    'fetch_time': datetime.now().isoformat(),
                                    'data_type': data_type,
                                    'source_url': url,
                                    'freshness': DataFreshness.REALTIME.value,
                                    'age_seconds': 0,
                                    'attempt': attempt + 1
                                }
                            }
                            
                            # æ›´æ–°æ•°æ®æºçŠ¶æ€
                            self.source_status[url] = {
                                'last_success': datetime.now().isoformat(),
                                'response_time': response.elapsed.total_seconds(),
                                'status': 'healthy'
                            }
                            
                            return enriched_data
                        else:
                            logger.warning(f"æ•°æ®è·å–å¤±è´¥: {response.status} - {url}")
                            
            except asyncio.TimeoutError:
                logger.warning(f"è¯·æ±‚è¶…æ—¶: {url} (å°è¯• {attempt + 1}/{config.retry_count})")
            except Exception as e:
                logger.error(f"æ•°æ®è·å–é”™è¯¯: {e} - {url}")
            
            # é‡è¯•å‰ç­‰å¾…
            if attempt < config.retry_count - 1:
                await asyncio.sleep(config.retry_delay_seconds)
        
        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        self.source_status[url] = {
            'last_failure': datetime.now().isoformat(),
            'status': 'unhealthy'
        }
        
        raise Exception(f"æ— æ³•è·å–æ•°æ®: {data_type} from {url}")
    
    def calculate_freshness(self, fetch_time: str) -> DataFreshness:
        """è®¡ç®—æ•°æ®æ–°é²œåº¦"""
        try:
            fetch_datetime = datetime.fromisoformat(fetch_time.replace('Z', '+00:00'))
            age_seconds = (datetime.now() - fetch_datetime).total_seconds()
            
            if age_seconds < 60:
                return DataFreshness.REALTIME
            elif age_seconds < 300:
                return DataFreshness.NEAR_REALTIME
            elif age_seconds < 900:
                return DataFreshness.RECENT
            else:
                return DataFreshness.STALE
        except:
            return DataFreshness.STALE
    
    def is_data_fresh(self, data: Dict[str, Any], config: RealTimeDataConfig) -> bool:
        """æ£€æŸ¥æ•°æ®æ˜¯å¦æ–°é²œ"""
        if 'metadata' not in data:
            return False
        
        metadata = data['metadata']
        fetch_time = metadata.get('fetch_time')
        
        if not fetch_time:
            return False
        
        freshness = self.calculate_freshness(fetch_time)
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¦æ±‚çš„æ–°é²œåº¦
        freshness_order = {
            DataFreshness.REALTIME: 4,
            DataFreshness.NEAR_REALTIME: 3,
            DataFreshness.RECENT: 2,
            DataFreshness.STALE: 1
        }
        
        return freshness_order.get(freshness, 0) >= freshness_order.get(config.required_freshness, 0)
    
    async def get_or_refresh_data(self, data_type: str, force_refresh: bool = False) -> Dict[str, Any]:
        """è·å–æˆ–åˆ·æ–°æ•°æ®"""
        config = self.data_configs.get(data_type)
        if not config:
            raise ValueError(f"æœªçŸ¥çš„æ•°æ®ç±»å‹: {data_type}")
        
        # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰æ•°æ®
        cached_data = self.data_cache.get(data_type)
        
        if cached_data and not force_refresh:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä»ç„¶æ–°é²œ
            if self.is_data_fresh(cached_data, config):
                logger.info(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {data_type}")
                return cached_data
            
            # æ•°æ®ä¸æ–°é²œï¼Œéœ€è¦åˆ·æ–°
            logger.info(f"æ•°æ®å·²è¿‡æœŸï¼Œåˆ·æ–°: {data_type}")
        
        # éœ€è¦è·å–æ–°æ•°æ®
        logger.info(f"è·å–å®æ—¶æ•°æ®: {data_type}")
        
        # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©æ•°æ®æº
        data_sources = self.get_data_sources(data_type)
        
        # å°è¯•ä»å¤šä¸ªæ•°æ®æºè·å–
        for source_name, source_info in data_sources.items():
            try:
                data = await self.fetch_realtime_data(
                    data_type, 
                    source_info['url'], 
                    source_info.get('params')
                )
                
                # æ›´æ–°ç¼“å­˜
                self.data_cache[data_type] = data
                
                # é€šçŸ¥è®¢é˜…è€…
                await self.notify_subscribers(data_type, data)
                
                return data
                
            except Exception as e:
                logger.error(f"æ•°æ®æº {source_name} å¤±è´¥: {e}")
                continue
        
        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
        if cached_data:
            logger.warning(f"æ‰€æœ‰æ•°æ®æºå¤±è´¥ï¼Œä½¿ç”¨è¿‡æœŸç¼“å­˜: {data_type}")
            return cached_data
        else:
            raise Exception(f"æ— æ³•è·å–æ•°æ®: {data_type}")
    
    def get_data_sources(self, data_type: str) -> Dict[str, Dict[str, Any]]:
        """è·å–æ•°æ®æºé…ç½®"""
        sources = {
            'financial_market': {
                'yahoo_finance': {
                    'url': 'https://query1.finance.yahoo.com/v8/finance/chart/%5EHSI',
                    'params': {'interval': '1m', 'range': '1d'}
                },
                'investing_com': {
                    'url': 'https://api.investing.com/api/financialdata/historical/179',
                    'params': {'interval': '1m', 'period': '1d'}
                }
            },
            'stock_prices': {
                'yahoo_quotes': {
                    'url': 'https://query1.finance.yahoo.com/v7/finance/quote',
                    'params': {'symbols': 'AAPL,MSFT,GOOGL'}
                }
            },
            'crypto_prices': {
                'coinbase': {
                    'url': 'https://api.coinbase.com/v2/prices/BTC-USD/spot'
                },
                'binance': {
                    'url': 'https://api.binance.com/api/v3/ticker/price',
                    'params': {'symbol': 'BTCUSDT'}
                }
            }
        }
        
        return sources.get(data_type, {})
    
    async def notify_subscribers(self, data_type: str, data: Dict[str, Any]):
        """é€šçŸ¥è®¢é˜…è€…"""
        if data_type in self.subscribers:
            for callback in self.subscribers[data_type]:
                try:
                    await callback(data_type, data)
                except Exception as e:
                    logger.error(f"é€šçŸ¥è®¢é˜…è€…å¤±è´¥: {e}")
    
    def subscribe(self, data_type: str, callback: callable):
        """è®¢é˜…æ•°æ®æ›´æ–°"""
        if data_type not in self.subscribers:
            self.subscribers[data_type] = []
        
        self.subscribers[data_type].append(callback)
        logger.info(f"æ–°çš„è®¢é˜…è€…: {data_type}")
    
    async def start_monitoring(self):
        """å¯åŠ¨æ•°æ®ç›‘æ§"""
        self.is_running = True
        logger.info("å®æ—¶æ•°æ®ç›‘æ§å¯åŠ¨")
        
        while self.is_running:
            try:
                # ç›‘æ§æ‰€æœ‰æ•°æ®ç±»å‹
                for data_type, config in self.data_configs.items():
                    try:
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
                        cached_data = self.data_cache.get(data_type)
                        needs_refresh = False
                        
                        if not cached_data:
                            needs_refresh = True
                        else:
                            metadata = cached_data.get('metadata', {})
                            fetch_time = metadata.get('fetch_time')
                            
                            if fetch_time:
                                fetch_datetime = datetime.fromisoformat(fetch_time.replace('Z', '+00:00'))
                                age_seconds = (datetime.now() - fetch_datetime).total_seconds()
                                
                                if age_seconds > config.refresh_interval_seconds:
                                    needs_refresh = True
                        
                        if needs_refresh:
                            await self.get_or_refresh_data(data_type)
                            
                    except Exception as e:
                        logger.error(f"ç›‘æ§ {data_type} å¤±è´¥: {e}")
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                await asyncio.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(30)  # é”™è¯¯åç­‰å¾…30ç§’
    
    async def stop_monitoring(self):
        """åœæ­¢æ•°æ®ç›‘æ§"""
        self.is_running = False
        logger.info("å®æ—¶æ•°æ®ç›‘æ§åœæ­¢")
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        status = {
            'is_running': self.is_running,
            'data_types_monitored': list(self.data_configs.keys()),
            'cache_size': len(self.data_cache),
            'subscriber_count': sum(len(subs) for subs in self.subscribers.values()),
            'source_health': self.source_status,
            'timestamp': datetime.now().isoformat()
        }
        
        # æ·»åŠ ç¼“å­˜æ•°æ®æ–°é²œåº¦ä¿¡æ¯
        freshness_info = {}
        for data_type, data in self.data_cache.items():
            if 'metadata' in data:
                metadata = data['metadata']
                fetch_time = metadata.get('fetch_time', '')
                freshness = self.calculate_freshness(fetch_time)
                
                freshness_info[data_type] = {
                    'freshness': freshness.value,
                    'fetch_time': fetch_time,
                    'age_seconds': (datetime.now() - datetime.fromisoformat(fetch_time.replace('Z', '+00:00'))).total_seconds() if fetch_time else 'unknown'
                }
        
        status['cache_freshness'] = freshness_info
        return status

# å…¨å±€å®æ—¶æ•°æ®ç³»ç»Ÿå®ä¾‹
realtime_system = RealTimeDataSystem()

async def ensure_realtime_data(data_type: str, max_age_seconds: int = 300) -> Dict[str, Any]:
    """
    ç¡®ä¿è·å–å®æ—¶æ•°æ®çš„è£…é¥°å™¨å‡½æ•°
    
    å‚æ•°:
        data_type: æ•°æ®ç±»å‹
        max_age_seconds: æœ€å¤§å…è®¸å¹´é¾„ï¼ˆç§’ï¼‰
    
    è¿”å›:
        å®æ—¶æ•°æ®
    """
    logger.info(f"ç¡®ä¿å®æ—¶æ•°æ®: {data_type}, æœ€å¤§å¹´é¾„: {max_age_seconds}ç§’")
    
    # è·å–æ•°æ®
    data = await realtime_system.get_or_refresh_data(data_type)
    
    # æ£€æŸ¥æ•°æ®æ–°é²œåº¦
    metadata = data.get('metadata', {})
    fetch_time = metadata.get('fetch_time')
    
    if fetch_time:
        fetch_datetime = datetime.fromisoformat(fetch_time.replace('Z', '+00:00'))
        age_seconds = (datetime.now() - fetch_datetime).total_seconds()
        
        if age_seconds > max_age_seconds:
            logger.warning(f"æ•°æ®å¹´é¾„ {age_seconds:.1f}ç§’ è¶…è¿‡é™åˆ¶ {max_age_seconds}ç§’")
            
            # å¼ºåˆ¶åˆ·æ–°
            data = await realtime_system.get_or_refresh_data(data_type, force_refresh=True)
    
    return data

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸš€ å®æ—¶æ•°æ®ç³»ç»Ÿç¤ºä¾‹")
    print("="*50)
    
    # å¯åŠ¨ç›‘æ§
    monitoring_task = asyncio.create_task(realtime_system.start_monitoring())
    
    try:
        # ç­‰å¾…ç³»ç»Ÿå¯åŠ¨
        await asyncio.sleep(2)
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        status = realtime_system.get_system_status()
        print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: {'è¿è¡Œä¸­' if status['is_running'] else 'å·²åœæ­¢'}")
        print(f"ğŸ“ˆ ç›‘æ§çš„æ•°æ®ç±»å‹: {', '.join(status['data_types_monitored'])}")
        
        # è·å–å®æ—¶é‡‘èæ•°æ®
        print("\nğŸ“Š è·å–å®æ—¶é‡‘èæ•°æ®...")
        try:
            financial_data = await ensure_realtime_data('financial_market', max_age_seconds=60)
            metadata = financial_data.get('metadata', {})
            print(f"âœ… æ•°æ®è·å–æˆåŠŸ")
            print(f"ğŸ•’ æ•°æ®æ—¶é—´: {metadata.get('fetch_time', 'æœªçŸ¥')}")
            print(f"âš¡ æ–°é²œåº¦: {metadata.get('freshness', 'æœªçŸ¥')}")
            print(f"ğŸ“¡ æ•°æ®æº: {metadata.get('source_url', 'æœªçŸ¥')}")
        except Exception as e:
            print(f"âŒ è·å–å¤±è´¥: {e}")
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´æŸ¥çœ‹è‡ªåŠ¨åˆ·æ–°
        print("\nâ³ ç­‰å¾…è‡ªåŠ¨åˆ·æ–°...")
        await asyncio.sleep(40)
        
        # å†æ¬¡æ£€æŸ¥çŠ¶æ€
        status = realtime_system.get_system_status()
        print(f"\nğŸ“Š åˆ·æ–°åç³»ç»ŸçŠ¶æ€:")
        for data_type, freshness_info in status.get('cache_freshness', {}).items():
            print(f"  â€¢ {data_type}: {freshness_info['freshness']} ({freshness_info['age_seconds']:.1f}ç§’å‰)")
        
    finally:
        # åœæ­¢ç›‘æ§
        await realtime_system.stop_monitoring()
        monitoring_task.cancel()
        
        try:
            await monitoring_task
        except asyncio.CancelledError:
            pass
        
        print("\nâœ… å®æ—¶æ•°æ®ç³»ç»Ÿç¤ºä¾‹å®Œæˆ")

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(example_usage())